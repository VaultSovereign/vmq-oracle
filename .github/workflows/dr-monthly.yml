name: DR Monthly (Trigger AWS-native pipeline and compare logs)
on:
  schedule:
    - cron: '0 3 1 * *'  # monthly at 03:00 UTC
  workflow_dispatch: {}
permissions:
  contents: read
  id-token: write

jobs:
  dr-check:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_QB_OIDC_ROLE_ARN }}
          aws-region: eu-west-1

      - name: Start AWS-native CodePipeline execution
        id: start
        env:
          PIPELINE_NAME: ${{ secrets.AWS_NATIVE_PIPELINE_NAME }}
        run: |
          set -euo pipefail
          exec_id=$(aws codepipeline start-pipeline-execution --name "$PIPELINE_NAME" --query pipelineExecutionId --output text)
          echo "exec_id=$exec_id" >> "$GITHUB_OUTPUT"

      - name: Ensure jq present
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq

      - name: Wait for pipeline to complete
        env:
          PIPELINE_NAME: ${{ secrets.AWS_NATIVE_PIPELINE_NAME }}
          EXEC_ID: ${{ steps.start.outputs.exec_id }}
        run: |
          set -euo pipefail
          for i in {1..120}; do
            s=$(aws codepipeline get-pipeline-execution --name "$PIPELINE_NAME" --pipeline-execution-id "$EXEC_ID" --query 'pipelineExecution.status' --output text)
            echo "[$i] $s"
            [[ "$s" =~ ^(Succeeded|Failed|Stopped|Superseded)$ ]] && break
            sleep 10
          done
          [[ "$s" == "Succeeded" ]]

      - name: Fetch CI and DR sync logs from S3
        env:
          BUCKET: ${{ secrets.QB_EXPORT_BUCKET }}
        run: |
          set -euo pipefail
          aws s3 cp "s3://${BUCKET}/ci/sync-jobs.json" ci-sync-jobs.json
          aws s3 cp "s3://${BUCKET}/_staging/dr/sync-jobs.json" dr-sync-jobs.json
          echo CI_SHA=$(sha256sum ci-sync-jobs.json | awk '{print $1}') >> "$GITHUB_ENV"
          echo DR_SHA=$(sha256sum dr-sync-jobs.json | awk '{print $1}') >> "$GITHUB_ENV"

      - name: Compare logs
        run: |
          set -euo pipefail
          echo "CI_SHA=$CI_SHA"
          echo "DR_SHA=$DR_SHA"
          if ! diff -u <(jq -S . ci-sync-jobs.json) <(jq -S . dr-sync-jobs.json); then
            echo "Mismatch between CI and DR sync logs" >&2
            exit 1
          fi

      - name: Promote staging → production (if identical)
        if: success()
        env:
          BUCKET: ${{ secrets.QB_EXPORT_BUCKET }}
        run: |
          set -euo pipefail
          echo "Promoting _staging → root..."
          aws s3 sync "s3://${BUCKET}/_staging/" "s3://${BUCKET}/" --delete

      - name: Write promotion audit record
        if: success()
        env:
          BUCKET: ${{ secrets.QB_EXPORT_BUCKET }}
        run: |
          set -euo pipefail
          TS=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
          cat > audit.json <<'JSON'
          {
            "event": "staging_promoted_to_production",
            "ts": "__TS__",
            "ci_sha": "__CI_SHA__",
            "dr_exec_id": "__DR_EXEC_ID__",
            "source_staging_prefix": "_staging/",
            "destination_prefix": "/",
            "performed_by": "dr-monthly@github-actions"
          }
JSON
          sed -i "s/__TS__/$TS/g" audit.json
          sed -i "s/__CI_SHA__/${GITHUB_SHA}/g" audit.json
          sed -i "s#__DR_EXEC_ID__#${{ steps.start.outputs.exec_id }}#g" audit.json
          aws s3 cp audit.json "s3://${BUCKET}/audit/promotions/promotion-${TS}.json"
          echo "✅ Wrote audit → s3://${BUCKET}/audit/promotions/promotion-${TS}.json"

      - name: Upload logs (artifact)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: dr-monthly-sync-logs-${{ github.run_id }}
          path: |
            ci-sync-jobs.json
            dr-sync-jobs.json
